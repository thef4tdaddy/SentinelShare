name: Daily Health Check

on:
  schedule:
    # Run every day at 8:00 AM US/Chicago (14:00 UTC)
    - cron: "0 14 * * *"
  workflow_dispatch: # Allow manual trigger

permissions:
  contents: read
  issues: write

jobs:
  full-salvo:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      # --- Setup ---
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "22"
          cache: "npm"
          cache-dependency-path: frontend/package-lock.json

      - name: Install Backend Dependencies
        run: |
          python -m venv venv
          source venv/bin/activate
          cd backend
          pip install -r ../requirements.txt
          pip install pytest pytest-cov black ruff mypy

      - name: Install Frontend Dependencies
        run: |
          cd frontend
          npm ci
          npx playwright install --with-deps

      # --- Backend Salvo ---
      - name: Backend Linting (Black, Ruff, Mypy)
        id: backend_lint
        run: |
          cd backend
          source ../venv/bin/activate
          set -o pipefail
          {
            EXIT_CODE=0
            
            echo "::group::Black"
            # Use '||' to prevent set -e from killing the script on failure
            python -m black --check . && BLACK_RES=0 || BLACK_RES=$?
            echo "STATUS_BLACK:$BLACK_RES"
            if [ $BLACK_RES -ne 0 ]; then EXIT_CODE=1; fi
            echo "::endgroup::"
            
            echo "::group::Ruff"
            python -m ruff check . && RUFF_RES=0 || RUFF_RES=$?
            echo "STATUS_RUFF:$RUFF_RES"
            if [ $RUFF_RES -ne 0 ]; then EXIT_CODE=1; fi
            echo "::endgroup::"
            
            echo "::group::Mypy"
            python -m mypy . --ignore-missing-imports && MYPY_RES=0 || MYPY_RES=$?
            echo "STATUS_MYPY:$MYPY_RES"
            if [ $MYPY_RES -ne 0 ]; then EXIT_CODE=1; fi
            echo "::endgroup::"
            
            exit $EXIT_CODE
          } 2>&1 | tee ../backend_lint.log
        continue-on-error: true

      - name: Backend Tests (Pytest)
        id: backend_test
        run: |
          cd backend
          source ../venv/bin/activate
          set -o pipefail
          # Run tests and output coverage report. Fail under 50%.
          {
            pytest --cov=. --cov-report=term-missing --cov-fail-under=50 tests/ && PYTEST_RES=0 || PYTEST_RES=$?
            echo "STATUS_PYTEST:$PYTEST_RES"
            exit $PYTEST_RES
          } 2>&1 | tee ../backend_test.log
        continue-on-error: true

      # --- Frontend Salvo ---
      - name: Frontend Linting (Prettier, ESLint, Svelte Check)
        id: frontend_lint
        run: |
          cd frontend
          set -o pipefail
          {
            EXIT_CODE=0
            
            echo "::group::Prettier"
            npx prettier --check "src/**/*.{ts,js,svelte,css}" && PRETTIER_RES=0 || PRETTIER_RES=$?
            echo "STATUS_PRETTIER:$PRETTIER_RES"
            if [ $PRETTIER_RES -ne 0 ]; then EXIT_CODE=1; fi
            echo "::endgroup::"
            
            echo "::group::ESLint"
            npm run lint && ESLINT_RES=0 || ESLINT_RES=$?
            echo "STATUS_ESLINT:$ESLINT_RES"
            if [ $ESLINT_RES -ne 0 ]; then EXIT_CODE=1; fi
            echo "::endgroup::"
            
            echo "::group::Svelte Check"
            npm run check && SVELTE_RES=0 || SVELTE_RES=$?
            echo "STATUS_SVELTE:$SVELTE_RES"
            if [ $SVELTE_RES -ne 0 ]; then EXIT_CODE=1; fi
            echo "::endgroup::"
            
            exit $EXIT_CODE
          } 2>&1 | tee ../frontend_lint.log
        continue-on-error: true

      - name: Frontend Tests (Vitest)
        id: frontend_test
        run: |
          cd frontend
          set -o pipefail
          {
            npm run test:run -- --coverage --coverage.thresholds.lines=50 && VITEST_RES=0 || VITEST_RES=$?
            echo "STATUS_VITEST:$VITEST_RES"
            exit $VITEST_RES
          } 2>&1 | tee ../frontend_test.log
        continue-on-error: true

      - name: Frontend E2E (Playwright)
        id: e2e
        run: |
          # Start Backend in Background
          cd backend
          source ../venv/bin/activate
          set -o pipefail

          # Generate a secure key for testing, ensuring consistency between Backend and Playwright
          export SECRET_KEY=$(python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())")

          # Fix: Include root directory in PYTHONPATH so 'backend' module is found
          export PYTHONPATH=$PYTHONPATH:$(pwd)/..

          # Use nohup to keep it running
          # Explicitly set DASHBOARD_PASSWORD empty to bypass auth for tests
          export DASHBOARD_PASSWORD=""
          nohup python -m uvicorn main:app --host 0.0.0.0 --port 8000 &

          # Wait for Backend to be ready
          echo "Waiting for Backend to start..."
          # Use curl with retry to avoid hard failure if it takes a sec
          curl --retry 5 --retry-delay 2 --retry-connrefused -s http://127.0.0.1:8000/api/health || { echo "ERROR: Backend failed to start"; exit 1; }
          echo "Backend started!"

          # Run Playwright
          cd ../frontend
             {
                npx playwright test && PW_RES=0 || PW_RES=$?
                echo "STATUS_PLAYWRIGHT:$PW_RES"
                exit $PW_RES
             } 2>&1 | tee ../e2e.log
        continue-on-error: true

      - name: File Size Audit
        id: file_sizes
        run: |
          chmod +x scripts/audit_file_sizes.sh
          ./scripts/audit_file_sizes.sh 500 2>&1 | tee file_sizes.log
        continue-on-error: true

      # --- Reporting ---
      - name: Generate Daily Health Report
        if: always()
        uses: actions/github-script@v7
        env:
          OUTCOME_BACKEND_LINT: ${{ steps.backend_lint.outcome }}
          OUTCOME_BACKEND_TEST: ${{ steps.backend_test.outcome }}
          OUTCOME_FRONTEND_LINT: ${{ steps.frontend_lint.outcome }}
          OUTCOME_FRONTEND_TEST: ${{ steps.frontend_test.outcome }}
          OUTCOME_E2E: ${{ steps.e2e.outcome }}
          OUTCOME_FILE_SIZES: ${{ steps.file_sizes.outcome }}
        with:
          script: |
            const fs = require('fs');
            const date = new Date().toLocaleDateString();

            // Helper to clean logs
            function stripAnsi(str) {
              return str.replace(/[\u001b\u009b][[()#;?]*(?:[0-9]{1,4}(?:;[0-9]{0,4})*)?[0-9A-ORZcf-nqry=><]/g, '');
            }

            // Read all logs
            const logs = {
              backend_lint: '',
              backend_test: '',
              frontend_lint: '',
              frontend_test: '',
              e2e: '',
              file_sizes: ''
            };

            for (const key of Object.keys(logs)) {
              try { 
                logs[key] = stripAnsi(fs.readFileSync(`${key}.log`, 'utf8')); 
              } catch (e) { 
                logs[key] = 'Log file not found (Step might have been skipped).'; 
              }
            }

            // --- Tool Status Parsing ---
            const tools = [
                { key: 'STATUS_BLACK', name: 'Black (Format)', log: logs.backend_lint, type: 'warning' },
                { key: 'STATUS_RUFF', name: 'Ruff (Lint)', log: logs.backend_lint, type: 'critical' },
                { key: 'STATUS_MYPY', name: 'Mypy (Type Check)', log: logs.backend_lint, type: 'critical' },
                { key: 'STATUS_PYTEST', name: 'Pytest (Unit)', log: logs.backend_test, type: 'critical' },
                { key: 'STATUS_PRETTIER', name: 'Prettier (Format)', log: logs.frontend_lint, type: 'warning' },
                { key: 'STATUS_ESLINT', name: 'ESLint (Lint)', log: logs.frontend_lint, type: 'critical' },
                { key: 'STATUS_SVELTE', name: 'Svelte Check (Types)', log: logs.frontend_lint, type: 'critical' },
                { key: 'STATUS_VITEST', name: 'Vitest (Unit)', log: logs.frontend_test, type: 'critical', outcome: process.env.OUTCOME_FRONTEND_TEST },
                { key: 'STATUS_PLAYWRIGHT', name: 'Playwright (E2E)', log: logs.e2e, type: 'critical', outcome: process.env.OUTCOME_E2E },
                { key: 'STATUS_FILE_SIZE', name: 'File Size Audit', log: logs.file_sizes, type: 'warning', outcome: process.env.OUTCOME_FILE_SIZES }
            ];

            let toolRows = [];
            let failures = [];
            let hasCriticalFailure = false;
            let hasWarningFailure = false;

            for (const tool of tools) {
                const match = tool.log.match(new RegExp(`${tool.key}:(\\d+)`));
                let statusIcon = 'â“';
                let outcome = 'UNKNOWN';
                
                if (match) {
                    const code = parseInt(match[1]);
                    if (code === 0) {
                        statusIcon = 'âœ…';
                        outcome = 'PASS';
                    } else {
                        // Determine failure icon based on severity
                        if (tool.type === 'critical') {
                            statusIcon = 'âŒ'; // Red Flag
                            hasCriticalFailure = true;
                        } else {
                            statusIcon = 'âš ï¸'; // Yellow Flag
                            hasWarningFailure = true;
                        }
                        outcome = 'FAIL';
                        failures.push(tool.name);
                    }
                } else if (tool.outcome === 'success') {
                     // Fallback to Actions outcome if log marker missing but step succeeded
                     statusIcon = 'âœ…';
                     outcome = 'PASS';
                } else if (tool.outcome === 'failure') {
                     statusIcon = (tool.type === 'critical') ? 'âŒ' : 'âš ï¸';
                     outcome = 'FAIL';
                     if (tool.type === 'critical') hasCriticalFailure = true; else hasWarningFailure = true;
                     failures.push(tool.name);
                } else if (!tool.log.includes('Log file not found')) {
                     // If log exists but marker missing and step didn't succeed
                     statusIcon = 'âŒ';
                     outcome = 'CRASH';
                     hasCriticalFailure = true;
                     failures.push(`${tool.name} (Crash)`);
                }

                toolRows.push(`| ${tool.name} | ${statusIcon} | ${outcome} |`);
            }

            // Determine Overall Status
            let overallStatus = 'success';
            let icon = 'âœ…';

            if (hasCriticalFailure) {
                overallStatus = 'failure';
                icon = 'ðŸš¨';
            } else if (hasWarningFailure) {
                overallStatus = 'warning';
                icon = 'âš ï¸';
            }

            const title = `${icon} Daily Health Report: ${date}`;

            // Build Summary Table
            const summaryTable = `| Tool | Status | Outcome |\n|---|---|---|\n${toolRows.join('\n')}\n`;

            // Helper to extract failure details (simplified)
            function getBriefLog(log) {
              if (!log) return '';
              const lines = log.split('\n');
              // Filter out the STATUS_ markers from the view
              const filtered = lines.filter(l => !l.includes('STATUS_'));
              
              const relevant = filtered.filter(l => 
                l.includes('FAILED') || l.includes('Error:') || l.includes('FAIL') || l.includes('âœ˜') || 
                l.includes('error') || l.includes('reformatted') || l.includes('would be reformatted')
              );
              
              if (relevant.length > 0) {
                 return relevant.slice(0, 15).join('\n') + (relevant.length > 15 ? '\n...' : '');
              }
              return filtered.slice(-15).join('\n');
            }

            // Build Detailed Body
            let details = '';

            // Add Oversized File Details
            const oversizedFileMatches = logs.file_sizes.match(/OVERSIZED_FILE:(.*):(\d+)/g);
            if (oversizedFileMatches) {
                details += `### ðŸ“ Oversized Files\n`;
                details += `| File | Lines | Threshold |\n|---|---|---|\n`;
                for (const line of oversizedFileMatches) {
                    const parts = line.split(':');
                    details += `| \`${parts[1]}\` | **${parts[2]}** | 500 |\n`;
                }
                details += `\n`;
            }

            // Only show logs for steps that had a failure
             if (failures.length > 0) {
                 details += `### âŒ Failure Details\n`;
                 // Naive mapping of tool failure to log file
                 const failedLogs = new Set();
                 
                  for (const tool of tools) {
                      if (toolRows.find(r => r.includes(tool.name) && r.includes('FAIL'))) {
                           if (tool.name.includes('Black') || tool.name.includes('Ruff') || tool.name.includes('Mypy')) failedLogs.add({ name: 'Backend Lint Log', log: logs.backend_lint });
                           if (tool.name.includes('Pytest')) failedLogs.add({ name: 'Backend Test Log', log: logs.backend_test });
                           if (tool.name.includes('Prettier') || tool.name.includes('ESLint') || tool.name.includes('Svelte')) failedLogs.add({ name: 'Frontend Lint Log', log: logs.frontend_lint });
                           if (tool.name.includes('Vitest')) failedLogs.add({ name: 'Frontend Test Log', log: logs.frontend_test });
                           if (tool.name.includes('Playwright')) failedLogs.add({ name: 'E2E Log', log: logs.e2e });
                      }
                  }
                  
                  for (const item of failedLogs) {
                      details += `#### ${item.name}\n\`\`\`\n${getBriefLog(item.log)}\n\`\`\`\n\n`;
                  }
             }

            const backendCov = getCoverageTable(logs.backend_test);
            const frontendCov = getCoverageTable(logs.frontend_test);

            if (backendCov) details += `### ðŸ“Š Backend Coverage\n\`\`\`\n${backendCov}\n\`\`\`\n\n`;
            if (frontendCov) details += `### ðŸ“Š Frontend Coverage\n\`\`\`\n${frontendCov}\n\`\`\`\n\n`;

            const fullBody = `**Full Salvo Verification Status**: ${overallStatus.toUpperCase()}

            ${summaryTable}

            ---
            ${details}

            [View Full Actions Log](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})`;

              // --- Issue Splitting & Creation ---
              // GitHub limits issue bodies to ~65,535 chars.
              const MAX_CHAR = 60000;
              let issueBody = fullBody;
              let remainingParts = [];

              if (fullBody.length > MAX_CHAR) {
                  // Find a good place to split (e.g., end of a section)
                  let splitIndex = fullBody.lastIndexOf('\n\n', MAX_CHAR);
                  if (splitIndex < 40000) splitIndex = MAX_CHAR; // Fallback if no clean break
                  
                  issueBody = fullBody.substring(0, splitIndex) + '\n\n**(Continued in comments...)**';
                  let remaining = fullBody.substring(splitIndex).trim();
                  
                  while (remaining.length > 0) {
                      let nextSplit = (remaining.length > MAX_CHAR) ? remaining.lastIndexOf('\n\n', MAX_CHAR) : remaining.length;
                      if (nextSplit < 40000 && remaining.length > MAX_CHAR) nextSplit = MAX_CHAR;
                      
                      remainingParts.push(remaining.substring(0, nextSplit).trim());
                      remaining = remaining.substring(nextSplit).trim();
                  }
              }

              const issue = await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: issueBody,
                labels: ['automated-report', 'daily-health', overallStatus]
              });

              for (const part of remainingParts) {
                  await github.rest.issues.createComment({
                      owner: context.repo.owner,
                      repo: context.repo.repo,
                      issue_number: issue.data.number,
                      body: part
                  });
              }

              // --- Auto-Create Coverage Tasks ---
              async function manageCoverageIssues(type, logSummary) {
                if (!logSummary || logSummary.includes('Log file not found')) return;
                
                const lines = logSummary.split('\n');
                const lowCoverageFiles = [];
                for (const line of lines) {
                    const row = line.split(/\s+|\|/).filter(Boolean);
                    if (row.length < 4) continue;
                    const filename = row[0];
                    if (!filename.includes('.') || filename === 'File' || filename === 'Name' || filename.includes('---')) continue;
                    
                    // Filter out files that don't typically need unit tests
                    const ignorePatterns = ['__init__.py', 'main.py', 'config.js', 'config.ts', 'vite.config', 'tailwind.config', 'postcss.config', 'playwright.config', 'setup.py'];
                    if (ignorePatterns.some(p => filename.includes(p))) continue;

                    const percentages = row.filter(item => item.match(/^\d+(\.\d+)?%?$/)).map(p => parseFloat(p));
                    const coverage = percentages.find(p => p < 80);
                    if (coverage !== undefined) {
                        lowCoverageFiles.push({ file: filename, coverage });
                    }
                }
                lowCoverageFiles.sort((a, b) => a.coverage - b.coverage);
                const candidates = lowCoverageFiles.slice(0, 3);
                for (const item of candidates) {
                    constParts = item.file.split('/');
                    const basename = constParts[constParts.length - 1].split('.')[0];
                    
                    const issueTitle = `test(${basename}): Improve coverage for ${item.file}`;
                    
                    const existing = await github.rest.search.issuesAndPullRequests({
                        q: `repo:${context.repo.owner}/${context.repo.repo} is:issue is:open "Improve coverage" "${item.file}"`
                    });
                    
                    if (existing.data.total_count === 0) {
                        await github.rest.issues.create({
                            owner: context.repo.owner,
                            repo: context.repo.repo,
                            title: issueTitle,
                            body: `Automated Coverage Task\n\nFile: \`${item.file}\`\nCurrent Coverage: **${item.coverage}%**\n\nRun \`daily-health-check\` to see progress.`,
                            labels: ['coverage-gap', 'help-wanted', `area:${type.toLowerCase()}`]
                        });
                        console.log(`Created task for ${item.file}`);
                    }
                }
            }

            try { await manageCoverageIssues('Backend', logs.backend_test); } catch(e) { console.error("Error managing backend coverage:", e); }
            try { await manageCoverageIssues('Frontend', logs.frontend_test); } catch(e) { console.error("Error managing frontend coverage:", e); }

            // --- Auto-Create Componentization Tasks (File Sizes) ---
            async function manageSizeIssues(log) {
                if (!log || log.includes('Log file not found')) return;
                
                const lines = log.split('\n');
                const oversizedFiles = [];
                for (const line of lines) {
                    if (line.startsWith('OVERSIZED_FILE:')) {
                        const parts = line.split(':');
                        oversizedFiles.push({ file: parts[1], lines: parseInt(parts[2]) });
                    }
                }

                for (const item of oversizedFiles) {
                    const parts = item.file.split('/');
                    const basename = parts[parts.length - 1];
                    const issueTitle = `refactor: Decomposition of ${basename}`;

                    const existing = await github.rest.search.issuesAndPullRequests({
                        q: `repo:${context.repo.owner}/${context.repo.repo} is:issue is:open "Decomposition of" "${item.file}"`
                    });

                    if (existing.data.total_count === 0) {
                        await github.rest.issues.create({
                            owner: context.repo.owner,
                            repo: context.repo.repo,
                            title: issueTitle,
                            body: `Automated Refactoring Task\n\nFile: \`${item.file}\` exceeds the recommended length threshold.\nCurrent Length: **${item.lines} lines** (Threshold: 500)\n\nThis file should be broken down into smaller, modular components or services to improve maintainability and testability.\n\nRun \`daily-health-check\` to see progress.`,
                            labels: ['refactoring', 'componentization', 'tech-debt']
                        });
                        console.log(`Created refactoring task for ${item.file}`);
                    }
                }
            }

            try { await manageSizeIssues(logs.file_sizes); } catch(e) { console.error("Error managing size issues:", e); }

            // Mark Run as Failed if Overall Status is failure
            if (overallStatus === 'failure') {
                core.setFailed("Daily Health Check failed. See report issue.");
            }
